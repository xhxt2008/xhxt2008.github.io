<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="技术是手段而不是目的"><title>平安产险2018极客挑战赛·初赛（三） | Tsukiyo</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'e5af71dc023cd2b9b7691d458518d79a';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
  </script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">平安产险2018极客挑战赛·初赛（三）</h1><a id="logo" href="/.">Tsukiyo</a><p class="description">天道宮</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/history/"><i class="fa fa-history"> 历史</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">平安产险2018极客挑战赛·初赛（三）</h1><div class="post-meta">Oct 10, 2018<span> | </span><span class="category"><a href="/categories/技术/">技术</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a class="disqus-comment-count" data-disqus-identifier="2018/10/10/pinganA3/" href="/2018/10/10/pinganA3/#disqus_thread"></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#特征工程"><span class="toc-number">1.</span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#删除极端值"><span class="toc-number">1.1.</span> <span class="toc-text">删除极端值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#确定被选择的特征数量"><span class="toc-number">1.2.</span> <span class="toc-text">确定被选择的特征数量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征选择"><span class="toc-number">1.3.</span> <span class="toc-text">特征选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#欠采样"><span class="toc-number">1.4.</span> <span class="toc-text">欠采样</span></a></li></ol></li></ol></div></div><div class="post-content"><h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>本次工作采用xgboost作为预测器，基于树模型的预测器对特征的质量相对敏感，因此是有必要做一些特征工程的。</p>
<h3 id="删除极端值"><a href="#删除极端值" class="headerlink" title="删除极端值"></a>删除极端值</h3><p>我们选择两个重要程度较大特征，并且把他们在一个二维平面以散点打印了出来。红色蓝色分别表示，正例和负例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cValues = pd.DataFrame(y_res)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cValues=cValues.replace(&#123;<span class="number">0</span>:<span class="string">'b'</span>,<span class="number">1</span>:<span class="string">'r'</span>&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.scatter(X_res[:,<span class="number">3</span>],X_res[:,<span class="number">16</span>],c=cValues.values[:,<span class="number">0</span>],marker = <span class="string">'.'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="http://ww1.sinaimg.cn/large/6b8ee255gy1fxkepu86iuj211y0zina4.jpg" alt="二维特征空间"><br>可以看出，在这个二维的特征空间里面，正负例几乎是重合的，这就很难只通过这两个特征做分类。而且，有一些点离群过于远了，这些异常点的存在会把大量有用信息压缩在一个很小的范围。我们认为应该予以删除这些点，获得更好的训练结果。</p>
<p>我们采用了基于knn的方法删除异常点，通过计算每个点最邻近的5个点的平均距离，删除最离群的0.3%的点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> LocalOutlierFactor</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lof = LocalOutlierFactor(n_neighbors=<span class="number">5</span>,contamination=<span class="number">0.003</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_pred = lof.fit_predict(X_train_select)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 补上index</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index_mumberid = X_train_select.index</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_predict=pd.Series(y_pred,index=index_mumberid)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留对应的点</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ANOMALY_DATA = <span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>predicted_outlier_index = np.where(y_pred == ANOMALY_DATA)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_outlier = X_train_select.iloc[predicted_outlier_index]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>plt.scatter(predicted_outlier[:,<span class="number">0</span>],predicted_outlier[:,<span class="number">1</span>],c=cValues1.values[:,<span class="number">0</span>],marker = <span class="string">'.'</span>)</span><br></pre></td></tr></table></figure>
<p>当然，这种基于knn的方法，在维度极高的情况下面临严重的维度爆炸的问题（效率及其低下）。在上一篇做了很多one-hot之后，维度已经变得高而稀疏。因此在做极端值删除之前，我们考虑先做特征选择。那么我们该留下多少特征呢？这又成为了一个新的问题。</p>
<h3 id="确定被选择的特征数量"><a href="#确定被选择的特征数量" class="headerlink" title="确定被选择的特征数量"></a>确定被选择的特征数量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>thresholds = np.sort(xgb_select.feature_importances_)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> thresh <span class="keyword">in</span> thresholds:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	<span class="comment"># select features using threshold</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	selection = SelectFromModel(xgb_select, threshold=thresh, prefit=<span class="keyword">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	select_X_train = selection.transform(X_train)</span><br><span class="line">	<span class="comment"># train model</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	selection_model = XGBClassifier(scale_pos_weight= <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	selection_model.fit(select_X_train, y_train,eval_metric = f_beta_wrapper)</span><br><span class="line">	<span class="comment"># eval model</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	select_X_train = selection.transform(X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	y_pred = selection_model.predict(select_X_train)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	predictions = [round(value) <span class="keyword">for</span> value <span class="keyword">in</span> y_pred]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	f2 = fbeta_score(y_train, predictions,beta=<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>	print(<span class="string">"Thresh=%.3f, n=%d, Accuracy: %.2f%%"</span> % (thresh, select_X_train.shape[<span class="number">1</span>], f2))</span><br><span class="line"></span><br><span class="line">Thresh=<span class="number">0.000</span>, n=<span class="number">51</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.001</span>, n=<span class="number">28</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.001</span>, n=<span class="number">28</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.003</span>, n=<span class="number">25</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.004</span>, n=<span class="number">24</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.006</span>, n=<span class="number">23</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.007</span>, n=<span class="number">21</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.014</span>, n=<span class="number">20</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.017</span>, n=<span class="number">19</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.025</span>, n=<span class="number">18</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.025</span>, n=<span class="number">18</span>, Accuracy: <span class="number">0.10</span>%</span><br><span class="line">Thresh=<span class="number">0.030</span>, n=<span class="number">14</span>, Accuracy: <span class="number">0.09</span>%</span><br><span class="line">Thresh=<span class="number">0.030</span>, n=<span class="number">14</span>, Accuracy: <span class="number">0.09</span>%</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>xgboost里的feature_importances_方法得出的值，是根据这个特征在全部迭代中被使用的次数决定的。我们根据feature_importance的重要性值，对全部特征进行排序，然后逐个设置阈值，不断减少特征数量进行初步的训练和预测。直到精度开始下降（一定程度）。这时需要的特征就被选择出来了。这里一共有20个重要特征（总数是57个）。</p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>imp_values=xgb_select.feature_importances_</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fea_names=train_df.columns.values</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>feature_importance=pd.Series(imp_values,index=fea_names)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fea_imp_order=feature_importance.sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fea_select =fea_imp_order.head(<span class="number">20</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_select = X_train.loc[:,fea_select.index]</span><br></pre></td></tr></table></figure>
<p>这一步简单的取出了前20个重要特征。</p>
<h3 id="欠采样"><a href="#欠采样" class="headerlink" title="欠采样"></a>欠采样</h3><p>前面提到，数据类别不平衡高达200:1。在这么大的不平衡级别下，即使我们通过自定义分类器的metrics也无法获得好的分类效果。根据几次简单的测试，我们认为应该把比例调整到10:1左右，才能获得好的学习效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> RandomUnderSampler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">ratio_multiplier</span><span class="params">(y)</span>:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    multiplier = &#123;<span class="number">0</span>: <span class="number">0.05</span>, <span class="number">1</span>: <span class="number">1</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    target_stats = Counter(y)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">for</span> key, value <span class="keyword">in</span> target_stats.items():</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        target_stats[key] = int(value * multiplier[key])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">return</span> target_stats</span><br><span class="line">    </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rus = RandomUnderSampler(random_state=<span class="number">100</span>,ratio=ratio_multiplier)<span class="comment">#100</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_res, y_res = rus.fit_sample(X_train_all, y_train_all)</span><br></pre></td></tr></table></figure>
<p>解决类别不平衡的手段除了欠采样，还有过采样和生成过采样等等。我们尝试了这些方法，发现这么做对精度并没有太大提高，还反而拖累了学习的效率。</p>
<p>到这里我们就得到了一个相对干净的数据集，可以开始训练了。</p>
</div><iframe src="/donate/?AliPayQR=/images/alipay.jpg&amp;WeChatQR=/images/wechatpay.jpg&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div><ul class="post-copyright"><li class="post-copyright-link"><span>本文链接：</span><a href="/2018/10/10/pinganA3/">平安产险2018极客挑战赛·初赛（三）</a></li><li class="post-copyright-author"><span>本文作者：</span><a href="/.">Tsukiyo</a></li><li class="post-copyright-license"><span>版权声明：</span>本文基于<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/cn/deed.zh">署名-非商业性使用-禁止演绎 3.0 中国大陆许可协议 (CC BY-NC-ND 3.0 CN)</a>发布，欢迎转载，但是必须保留本文的署名<a href="https://xhxt2008.github.io/">Tsukiyo</a>及链接。如果要用于商业目的，请联系作者。</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://xhxt2008.github.io/2018/10/10/pinganA3/" data-id="cjp6g70we000qdjxt16bz1qrn" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACJUlEQVR42u3aQXKDMAwF0Nz/0ukBUsiXBJ1iP68ywYAfC40s+fWKx/tjHF09mv951/m7XncMDAyMxzLep+NooefPmf+Trw0DA2Mfxnngy4Ns9QNV33v4PwYGBkYxHTwP00lwx8DAwJgwqmF0MgcDAwOjuolN5k+e9kd7cQwMjAcyqsX6v/x9S38DAwPjUYxeuJwEzeQDlVeFgYGxNCMPcAkmnzlplB7OxMDAWJRxXzI32WomH+v2vBUDA+OfMa5qDMzTvrxJcJjhYmBgLMfIm4i91DAPnb0GAAYGxp6MJBWbLzEHVz8TBgbG2ozqIa3896SFMDpggYGBsQTjqtStGqx7qeThVQwMjKUZk0JYXpOfPyEqt2FgYCzKmBTXyo3GYoOhEJoxMDCWZvSOgvWWON97vnoDAwPj4YxJ+MsPQMwPmUWpIQYGxgaMakKWl9WSIxS9RLNwMwYGxmMZSVsx4eVN0F54jXgYGBgbMPLQedWWOG8SRI0EDAyMbRjzul3vSFkvQP/S5cDAwNiAUS29TcpneTshalFgYGBsyehtWZONcRJk89ViYGCszXgXR5II5os7TwTzQI+BgbE249piWbIN7h2qKBTdMDAwFmUk4XJy/OuqgPvlXgwMjA0Y1cCXvKY3v4fHwMDA6AXQvOWQFPi+rAcDAwPjoiOnvSAeNSowMDA2YCSb2HyjO3lyNT3FwMDYgVE94jBZRG9De1kjEwMD43mMH6ywapjrwkaHAAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/特征工程/">特征工程</a><a href="/tags/机器学习/">机器学习</a><a href="/tags/数据分析/">数据分析</a><a href="/tags/竞赛/">竞赛</a><a href="/tags/平安产险/">平安产险</a></div><div class="post-nav"><a class="next" href="/2018/09/19/pinganA2/">平安产险2018极客挑战赛·初赛（二）</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://xhxt2008.github.io/2018/10/10/pinganA3/';
    this.page.identifier = '2018/10/10/pinganA3/';
    this.page.title = '平安产险2018极客挑战赛·初赛（三）';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//https-xhxt2008-github-io.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//https-xhxt2008-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://https-xhxt2008-github-io.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><input class="st-default-search-input" placeholder="Search" type="text"/></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/日志/">日志</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂记/">杂记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/研究/">研究</a><span class="category-list-count">7</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/动态表情/" style="font-size: 15px;">动态表情</a> <a href="/tags/特征选择/" style="font-size: 15px;">特征选择</a> <a href="/tags/未翻译/" style="font-size: 15px;">未翻译</a> <a href="/tags/英文/" style="font-size: 15px;">英文</a> <a href="/tags/社交网络/" style="font-size: 15px;">社交网络</a> <a href="/tags/意见领袖/" style="font-size: 15px;">意见领袖</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/聚类/" style="font-size: 15px;">聚类</a> <a href="/tags/人脸表情识别/" style="font-size: 15px;">人脸表情识别</a> <a href="/tags/人脸识别/" style="font-size: 15px;">人脸识别</a> <a href="/tags/表情识别/" style="font-size: 15px;">表情识别</a> <a href="/tags/论文查找/" style="font-size: 15px;">论文查找</a> <a href="/tags/日文/" style="font-size: 15px;">日文</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/VC维/" style="font-size: 15px;">VC维</a> <a href="/tags/时间序列/" style="font-size: 15px;">时间序列</a> <a href="/tags/特征工程/" style="font-size: 15px;">特征工程</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a> <a href="/tags/数据分析/" style="font-size: 15px;">数据分析</a> <a href="/tags/竞赛/" style="font-size: 15px;">竞赛</a> <a href="/tags/平安产险/" style="font-size: 15px;">平安产险</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/动态规划/" style="font-size: 15px;">动态规划</a> <a href="/tags/动漫/" style="font-size: 15px;">动漫</a> <a href="/tags/人渣的本愿/" style="font-size: 15px;">人渣的本愿</a> <a href="/tags/剧透/" style="font-size: 15px;">剧透</a> <a href="/tags/评论/" style="font-size: 15px;">评论</a> <a href="/tags/茶太/" style="font-size: 15px;">茶太</a> <a href="/tags/歌词翻译/" style="font-size: 15px;">歌词翻译</a> <a href="/tags/同人音乐/" style="font-size: 15px;">同人音乐</a> <a href="/tags/数据可视化/" style="font-size: 15px;">数据可视化</a> <a href="/tags/knn/" style="font-size: 15px;">knn</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/10/10/pinganA3/">平安产险2018极客挑战赛·初赛（三）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/19/pinganA2/">平安产险2018极客挑战赛·初赛（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/11/pinganA1/">平安产险2018极客挑战赛·初赛（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/11/VC-dimension/">通俗易懂，什么是VC维</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/07/deep-learning/">上帝归上帝，恺撒归凯撒，传统方法与深度学习之辨。</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/21/Combining-feature-selection/">Combining multiple feature selection methods for stock prediction Union, intersection, and multi-intersection approaches</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/30/look-same/">Paper Survey about Do They All Look the Same Deciphering Chinese, Japanese and Koreans by Fine-Grained Deep Learning.</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/30/OLM/">Paper Survey about Mining Opinion Leaders in Big Social Network</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/22/paper-survey-kyoto/">Paper survey about Timing-Based Facial Expression Recognition of Kyoto University by Prof. Kawashima 　</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/22/Face-expression-recognition/">Paper survey about Face Expression Recognition</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//https-xhxt2008-github-io.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.sitixi.com" title="STONEX" target="_blank">STONEX</a><ul></ul><a href="https://mirukuchan.github.io/" title="Miruku" target="_blank">Miruku</a><ul></ul><a href="https://stefenson.github.io" title="Stefenson" target="_blank">Stefenson</a><ul></ul><a href="http://gunx.info/" title="Gunx" target="_blank">Gunx</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Tsukiyo.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script>(function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
(w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
})(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
_st('install','HyWyJnTdw-UKr1LBb7JD','2.0.0');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>